% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/irtplay-package.R
\docType{package}
\name{irtplay-package}
\alias{irtplay-package}
\title{irtplay: Evaluation of model-data fit in Item Response Theory (IRT) and
useful functions related to IRT}
\description{
Examine the IRT model-data fit on item-level in different ways as well as provide
useful functions related to unidimensional item response theory (IRT). In terms of assessing the IRT model-data fit,
one of distinguished features of this package is that it gives not only item fit statistics (e.g., \eqn{\chi^{2}}
fit statistic (e.g., Bock, 1960; Yen, 1981), infit and outfit statistics (Ames et al., 2015), and \eqn{S-X^{2}}
(Orlando & Thissen, 2000, 2003)) but also graphical displays to look at residuals between between the observed
data and model-based predictions (Hambleton, Swaminathan, & Rogers, 1991). More evaluation methods will be included
in the future updated version.
In addition to the evaluation of IRT model-data fit, there are several useful functions such as estimating proficiency
parameters, , calibrating item parameters given the fixed effects (aka. ability values), computing asymptotic
variance-covariance matrices of item parameter estimates, importing item and/or ability parameters from popular IRT software,
generating simulated data, computing the conditional distribution of observed scores using the Lord-Wingersky recursion formula,
computing item and test information functions, computing item and test characteristic curve functions, and plotting item and test
characteristic curves and item and test information functions.

\tabular{ll}{ Package: \tab irtplay\cr Version: \tab 1.0.0\cr Date: \tab
2019-08-22\cr Depends: \tab R (>= 3.4)\cr License: \tab GPL (>= 2)\cr }
}
\details{
One way to assess goodness of IRT model-data fit is through an item fit analysis by examining the traditional item fit statistics
and looking at the discrepancy between the observed data and model-based predictions. Using \pkg{irtplay} package, the traditional approach
of evaluating the IRT model-data fit on item-level can be implemented with three main steps:

\enumerate{
  \item Prepare a data set for the IRT item fit analysis (i.e., item meta data, ability estimates, and response data).
  \item Obtain the IRT fit statistics such as \eqn{\chi^{2}}, infit, and outfit statistics using the function \code{\link{irtfit}}.
  \item Based on the results of IRT model fit analysis (i.e., an object of class \code{\link{irtfit}}) obtained in step 2,
draw the IRT residual plots (i.e., raw residual and standardized residual plots) using the function \code{\link{plot.irtfit}}.
}

\describe{
  \item{1. Preparing a data set}{
  Before conducting the IRT model fit analysis, it is necessary to prepare a data set. To run the function \code{\link{irtfit}}, it requires
  three data sets:

   \enumerate{
   \item Item meta data including the item ID, number of score categories, IRT models, and item parameters. The item meta data should be in the format of
   data.frame. You can prepare the data either by using the function \code{\link{shape_df}} or by creating a data.frame of the item meta data by yourself.
   If you have output files of item parameter estimates obtained from one of the IRT software such as BILOG-MG 3, PARSCALE 4, flexMIRT, and mirt (R package),
   the item meta data can be easily obtained using the functions of \code{\link{bring.bilog}}, \code{\link{bring.parscale}}, \code{\link{bring.flexmirt}},
   and \code{\link{bring.mirt}}. See \code{\link{irtfit}}, \code{\link{test.info}}, or \code{\link{simdat}} for more details about the item meta data format.
   \item Examinees' ability (or proficiency) estimates. It should be in the format of a numeric vector.
   \item Examinees' response data set for the items. It should be in the format of matrix where a row and column indicate the examinees and the items,
   respectively. The order of the examinees in the response data set must be exactly the same as that of the examinees' ability estimates. The order of the items
   in the response data set must be exactly the same as that of the items in the item meta data.
   }

 }

  \item{2. Computing the IRT model-data fit statistics}{
  The function \code{\link{irtfit}} computes the traditional IRT item fit statistics such as \eqn{\chi^{2}}, infit, and outfit statistics.
  To calculate the \eqn{\chi^{2}} statistic, two methods are available to divide the ability scale into several groups. The two methods are "equal.width"
  for dividing the scale by an equal length of the interval and "equal.freq" for dividing the scale by an equal frequency of examinees. Also, you need to
  specify the location of ability point at each group (or interval) where the expected probabilities of score categories are calculated from the IRT models.
  Available locations are "average" for computing the expected probability at the average point of examinees' ability estimates in each group and "middle" for
  computing the expected probability at the midpoint of each group.

  To use the function \code{\link{irtfit}}, you need to insert the item meta data in the argument \code{x}, the ability estimates in the argument \code{score},
  and the response data in the argument \code{data}. If you want to divide the ability scale into other than ten groups, you need to specify the number of groups
  in the argument \code{n.width}. In addition, if the response data include missing values, you must indicate the missing value in argument \code{missing}.

  Once the function \code{\link{irtfit}} has been implemented, you'll get the fit statistic results and the contingency tables for every item used
  to calculate the \eqn{\chi^{2}} fit statistic.
 }

  \item{3. Drawing the IRT residual plots}{
  Using the saved object of class \code{\link{irtfit}}, you can use the \code{\link{plot}} method to evaluate the IRT raw residual and standardized residual plots.

  Because the \code{\link{plot}} method can draw the residual plots for an item at a time, you have to indicate which item will be examined. For this,
  you can specify an integer value, which is the location of the studied item, in the argument \code{item.loc}.

  In terms of the raw residual plot, the argument \code{ci.method} is used to select a method to estimate the confidence intervals among four methods.
  Those methods are "wald" for the Wald interval, which is based on the normal approximation (Laplace, 1812), "cp" for Clopper-Pearson interval
  (Clopper & Pearson, 1934), "wilson" for Wilson score interval (Wilson, 1927), and "wilson.cr" for Wilson score interval with continuity correction
  (Newcombe, 1998).
 }
}
}
\section{Example code for the three main steps}{


The example code below shows how to prepare the data sets and how to conduct the IRT model-data fit analysis:\preformatted{
##---------------------------------------------------------------
# Attach the packages
library(irtplay)

##---------------------------------------------------------------
## Step 1: prepare a data set for IRT
## In this example, we use the simulated mixed-item format of CAT Data
## But, only items that have examinees' responses more than 1,000 are assessed.

# find the location of items that have more than 1,000 item responses
over1000 <- which(colSums(simCAT_MX$res.dat, na.rm=TRUE) > 1000)

# (1) item meta data
x <- simCAT_MX$item.prm[over1000, ]

# (2) examinee's ability estimates
score <- simCAT_MX$score

# (3) response data
data <- simCAT_MX$res.dat[, over1000]

##---------------------------------------------------------------
## Step 2: Compute the IRT mode-data fit statistics
# (1) the use of "equal.width"
fit1 <- irtfit(x=x, score=score, data=data, group.method="equal.width",
               n.width=10, loc.theta="average", range.score=NULL, D=1,
               alpha=0.05, missing=NA)

# what kinds of internal objects does the results have?
names(fit1)

# show the results of the fit statistics
fit1$fit_stat[1:10, ]

# show the contingency tables for the first item (dichotomous item)
fit1$contingency[[1]]

# (2) the use of "equal.freq"
fit2 <- irtfit(x=x, score=score, data=data, group.method="equal.freq",
               n.width=10, loc.theta="average", range.score=NULL, D=1,
               alpha=0.05, missing=NA)

# show the results of the fit statistics
fit2$fit_stat[1:10, ]

# show the contingency table for the fourth item (polytomous item)
fit2$contingency[[4]]

##---------------------------------------------------------------
## Step 3: Draw the IRT residual plots
# 1. for the dichotomous item
# (1) both raw and standardized residual plots using the object "fit1"
plot(x=fit1, item.loc=1, type = "both", ci.method = "wald",
     ylim.sr.adjust=TRUE)

# (2) the raw residual plots using the object "fit1"
plot(x=fit1, item.loc=1, type = "icc", ci.method = "wald",
     ylim.sr.adjust=TRUE)

# (3) the standardized residual plots using the object "fit1"
plot(x=fit1, item.loc=113, type = "sr", ci.method = "wald",
     ylim.sr.adjust=TRUE)

# 2. for the polytomous item
# (1) both raw and standardized residual plots using the object "fit1"
plot(x=fit1, item.loc=113, type = "both", ci.method = "wald",
     ylim.sr.adjust=TRUE)

# (2) the raw residual plots using the object "fit1"
plot(x=fit1, item.loc=113, type = "icc", ci.method = "wald",
     layout.col=2, ylim.sr.adjust=TRUE)

# (3) the standardized residual plots using the object "fit1"
plot(x=fit1, item.loc=113, type = "sr", ci.method = "wald",
     layout.col=4, ylim.sr.adjust=TRUE)
}
}

\section{IRT Models}{


In \pkg{irtplay} package, both dichotomous and polytomous IRT models are available.
For dichotomous items, IRT one-, two-, and three-parameter logistic models are used. For polytomous items,
the graded response model (GRM) and the (generalized) partial credit model (GPCM) are used.
Note that the item discrimination (or slope) parameters should be fixed to 1 when the partial credit model is used.
The IRT model parameter labels use the conventions shown below. Note that \eqn{M} is the total number of categories
for each of polytomous item.

\describe{
  \item{IRT 1-3PL models}{
    For the IRT 1-3PL models, the probability that an examinee with \eqn{\theta} provides a correct answer for an item is given by,
     \deqn{P(u = 1|\theta) = g + \frac{(1 - g)}{1 + exp(-Da(\theta - b))},}
    where \eqn{D} is a scaling factor. When the IRT 1PL model is used, \eqn{a} is fixed to a constant and \eqn{g = 0}
    for all items. When the IRT 2PL model is used, \eqn{g = 0}.
  }
  \item{GRM}{
    For the graded response model, the probability that an examinee with \eqn{\theta} scores \eqn{k} on an item with \eqn{M} categories
    is a given by,
    \deqn{P(u = k | \theta) = P(x \ge k | \theta) - P(x \ge k + 1 | \theta),}
    \deqn{P(x \ge k | \theta) = \frac{1}{1 + exp(-Da(\theta - b_{k}))}, }
    \deqn{P(x \ge k + 1 | \theta) = \frac{1}{1 + exp(-Da(\theta - b_{k+1}))}, }
    where \eqn{b_{k}} is the \eqn{k}th threshold parameter for an item.
  }
  \item{GPCM}{
    For the (generalized) partial credit model, the probability that an examinee with \eqn{\theta} scores \eqn{k} on an item with \eqn{M}
    categories is a given by,
     \deqn{P(u = k | \theta) = \frac{exp(\sum_{u=0}^{k}{Da(\theta - b_{u})})}{\sum_{j=0}^{M-1}{exp(\sum_{u=0}^{j}{Da(\theta - b_{u})})}},}
    where \eqn{b_{u}} is the \eqn{u}th step parameter for an item. In other contexts, the step parameter \eqn{b_{u}} can
    also be parameterized as \eqn{b_{u} = \beta - \tau_{u}}, where \eqn{\beta} denotes the location (or overall difficulty) parameter
    and \eqn{\tau_{u}} represents a difficulty (or threshold) parameter for each category. In this package, only the step parameter of \eqn{b_{u}}
    is only used. Also, note that M-1 step parameters are necessary when an item has M categories because a step parameter for the first category
    does not affect the category probabilities. When a partial credit model is used, \eqn{a = 1}.
   }

}
}

\references{
Ames, A. J., & Penfield, R. D. (2015). An NCME Instructional Module on Item-Fit Statistics for Item Response Theory Models.
\emph{Educational Measurement: Issues and Practice, 34}(3), 39-48.

Baker, F. B., & Kim, S. H. (2004). \emph{Item response theory: Parameter estimation techniques.} CRC Press.

Birnbaum, A. (1968). Some latent trait models and their use in inferring an examinee's ability. In F. M. Lord & M. R. Novick (Eds.),
\emph{Statistical theories of mental test scores} (pp. 397-479). Reading, MA: Addison-Wesley.

Bock, R.D. (1960), \emph{Methods and applications of optimal scaling}. Chapel Hill, NC: L.L. Thurstone Psychometric Laboratory.

Bock, R. D., & Mislevy, R. J. (1982). Adaptive EAP estimation of ability in a microcomputer environment. \emph{Psychometrika, 35}, 179-198.

Cai, L. (2017). flexMIRT 3.5 Flexible multilevel multidimensional item analysis and test scoring [Computer software].
Chapel Hill, NC: Vector Psychometric Group.

Chalmers, R. P. (2012). mirt: A multidimensional item response theory package for the R environment.
\emph{Journal of Statistical Software, 48}(6), 1-29.

Clopper, C. J., & Pearson, E. S. (1934). The use of confidence or fiducial limits illustrated in the case of the binomial.
\emph{Biometrika, 26}(4), 404-413.

Hambleton, R. K., & Swaminathan, H., & Rogers, H. J. (1991) \emph{Fundamentals of item response theory}.
Newbury Park, CA: Sage.

Kang, T., & Chen, T. T. (2008). Performance of the generalized S-X2 item fit index for polytomous IRT models.
\emph{Journal of Educational Measurement, 45}(4), 391-406.

Kolen, M. J. & Brennan, R. L. (2004) \emph{Test Equating, Scaling, and Linking} (2nd ed.). New York:
Springer.

Laplace, P. S. (1820).\emph{Theorie analytique des probabilites} (in French). Courcier.

Li, Y. & Lissitz, R. (2004). Applications of the analytically derived asymptotic standard errors of item response theory
item parameter estimates. \emph{Journal of educational measurement, 41}(2), 85-117.

Lord, F. & Wingersky, M. (1984). Comparison of IRT true score and equipercentile observed score equatings.
\emph{Applied Psychological Measurement, 8}(4), 453-461.

Muraki, E. & Bock, R. D. (2003). PARSCALE 4: IRT item analysis and test scoring for rating
scale data [Computer Program]. Chicago, IL: Scientific Software International. URL http://www.ssicentral.com

Newcombe, R. G. (1998). Two-sided confidence intervals for the single proportion: comparison of seven methods.
\emph{Statistics in medicine, 17}(8), 857-872.

Orlando, M., & Thissen, D. (2000). Likelihood-based item-fit indices for dichotomous item response theory models.
\emph{Applied Psychological Measurement, 24}(1), 50-64.

Orlando, M., & Thissen, D. (2003). Further investigation of the performance of S-X2: An item fit index for use with
dichotomous item response theory models. \emph{Applied Psychological Measurement, 27}(4), 289-298.

Pritikin, J. (2018). \emph{rpf: Response Probability Functions}. R package version 0.59.
https://CRAN.R-project.org/package=rpf.

Thissen, D., Pommerich, M., Billeaud, K., & Williams, V. S. (1995). Item Response Theory
for Scores on Tests Including Polytomous Items with Ordered Responses. \emph{Applied Psychological
Measurement, 19}(1), 39-49.

Thissen, D. & Orlando, M. (2001). Item response theory for items scored in two categories. In D. Thissen & H. Wainer (Eds.),
\emph{Test scoring} (pp.73-140). Mahwah, NJ: Lawrence Erlbaum.

Weeks, J. P. (2010). plink: An R Package for Linking Mixed-Format Tests Using IRT-Based Methods.
\emph{Journal of Statistical Software, 35}(12), 1-33. URL http://www.jstatsoft.org/v35/i12/.

Wilson, E. B. (1927). Probable inference, the law of succession, and statistical inference.
\emph{Journal of the American Statistical Association, 22}(158), 209-212.

Yen, W. M. (1981). Using simulation results to choose a latent trait model. \emph{Applied Psychological Measurement, 5}, 245-262.

Zimowski, M. F., Muraki, E., Mislevy, R. J., & Bock, R. D. (2003). BILOG-MG 3: Multiple-group
IRT analysis and test maintenance for binary items [Computer Program]. Chicago, IL: Scientific
Software International. URL http://www.ssicentral.com
}
\author{
Hwanggyu Lim \email{hglim83@gmail.com}
}
\keyword{package}
